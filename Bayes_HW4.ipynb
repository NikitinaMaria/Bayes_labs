{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Байесовский выбор моделей\n",
        "## Домашняя работа №4\n",
        "### Никитина Мария, Б05-003"
      ],
      "metadata": {
        "id": "k6E8vE7600Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим вероятностную модель метода главных компонент, считая, что для каждого объекта $\\mathbf{x}_i \\in \\mathbb{R}^n$ существует описание $\\mathbf{z}_i \\in \\mathbb{R}^d$ в признаковом пространстве меньшей размерности, причем $\\mathbf{x}_i = \\mathbf{W}\\mathbf{z}_i + \\mathbf{\\mu} + \\mathbf{\\varepsilon}_i$, где $\\mathbf{\\mu} \\in \\mathbb{R}^n$ – есть некоторое смещение (на случай нецентрированности признаков), а $\\mathbf{\\varepsilon}_i \\in \\mathbb{R}^n$ –\n",
        "шумовой вектор.\n",
        "\n",
        "Пусть имеется выборка $\\mathbf{X} = [\\mathbf{x}_1, . . . , \\mathbf{x}_m]$ независимых объектов. Пусть\n",
        "\n",
        "$$p(\\mathbf{z}_i) = N(\\mathbf{z}_i|\\mathbf{0}, \\mathbf{I}), ~~~ p(\\mathbf{\\varepsilon}_i) = N(\\mathbf{\\varepsilon}_i|\\mathbf{0}, \\sigma^2\\mathbf{I}).$$\n",
        "\n",
        "Считая $\\mathbf{W}, \\sigma^2, \\mathbf{\\mu}$ - неизвестными параметрами задачи, а $d$ фиксированным\n",
        "\n",
        "а) выписать $p(\\mathbf{X}, \\mathbf{Z}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma)$ (3 балла)"
      ],
      "metadata": {
        "id": "dKf1-afi1qtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$p(\\mathbf{X}, \\mathbf{Z}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma) = \\prod\\limits_{i = 1}^m p(\\mathbf{x}_i|\\mathbf{z}_i \\mathbf{W}, \\mathbf{\\mu}, \\sigma) p(\\mathbf{z}_i) = \\prod\\limits_{i = 1}^m N(\\mathbf{x}_i|\\mathbf{\\mu} + \\mathbf{W}\\mathbf{z}_i, \\sigma^2\\mathbf{I})N(\\mathbf{z}_i|\\mathbf{0}, \\mathbf{I})$$"
      ],
      "metadata": {
        "id": "8-b0wIhT4Plx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "б) найти $p(\\mathbf{X}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma)$ (3 балла)"
      ],
      "metadata": {
        "id": "BXRdAxMT5qsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$p(\\mathbf{X}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma) = \\prod\\limits_{i = 1}^m\\int p(\\mathbf{x}_i, \\mathbf{z}_i|\\mathbf{W}, \\mathbf{\\mu}, \\sigma)d\\mathbf{z}_i = \\prod\\limits_{i = 1}^m N(\\mathbf{x}_i| \\mathbf{\\mu}, \\sigma^2\\mathbf{I} + \\mathbf{W}\\mathbf{W}^\\top)$$"
      ],
      "metadata": {
        "id": "cLzpqmpH551D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "в) с помощью EM-алгоритма решить задачу нахождения наиболее правдоподобных оценок $\\mathbf{W}, \\mathbf{\\mu}, \\sigma$, то есть решить задачу\n",
        "\n",
        "$$p(\\mathbf{X}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma) \\to \\underset{\\mathbf{W}, \\mathbf{\\mu}, \\sigma}{\\max},$$\n",
        "\n",
        "получив итеративные формулы пересчета для E и M шагов (25 баллов). Каково апостериорное распределение $p(\\mathbf{z}_i|\\mathbf{x}_i, \\mathbf{W}, \\sigma, \\mathbf{\\mu})$? (10 баллов) Как изменить вероятностную модель, чтобы\n",
        "учесть, что в данных есть пропуски? (10 баллов)\n"
      ],
      "metadata": {
        "id": "0Dkh-TmthLYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E - шаг (считаем $\\mathbf{\\mu}, \\sigma^2$ фиксированными):\n",
        "\n",
        "На Е шаге найдём $q(\\mathbf{z}_i) = p(\\mathbf{z}_i|\\mathbf{x}_i, \\mathbf{W}, \\mathbf{\\mu}, \\sigma^2)$. Оно пропорционально совместному, то есть будет нормальным распределением. Тогда\n",
        "\n",
        "$$F(q, \\mathbf{\\mu}, \\sigma^2) \\to \\underset{q}{\\max} \\Rightarrow q(\\mathbf{z}_i) = p(\\mathbf{z}_i|\\mathbf{x}_i, \\mathbf{W}, \\mathbf{\\mu}, \\sigma^2) = N(\\mathbf{m}_i, A)$$\n",
        "\n",
        "$$\\frac{1}{\\sigma^2}(\\mathbf{x}_i - \\mathbf{W}\\mathbf{z}_i - \\mathbf{\\mu})^\\top(\\mathbf{x}_i - \\mathbf{W}\\mathbf{z}_i - \\mathbf{\\mu}) + \\mathbf{z}_i^\\top\\mathbf{z}_i \\sim (\\mathbf{z}_i - \\mathbf{m}_i)^\\top A^{-1} (\\mathbf{z}_i - \\mathbf{m}_i)$$\n",
        "\n",
        "$$A^{-1} = \\frac{\\mathbf{W}^\\top \\mathbf{W}}{\\sigma^2} + \\mathbf{I}, ~~~ \\mathbf{m}_i = \\frac{A^\\top \\mathbf{W}^\\top}{\\sigma^2}(\\mathbf{x}_i - \\mathbf{\\mu})$$\n",
        "\n",
        "M - шаг (считаем $q(\\mathbf{Z})$ фиксированным):\n",
        "\n",
        "$$E_{q(\\mathbf{Z})} \\log p(\\mathbf{X}, \\mathbf{Z}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma) = E_{q(\\mathbf{Z})}\\sum\\limits_{i = 1}^m\\left(-\\log (2\\pi)^{\\frac{n}{2}} \\sigma^n - \\frac{1}{2\\sigma^2}\\|x_i- (\\mu + W z_i)\\|^2 - \\log (2\\pi)^{\\frac{d}{2}} - \\|z_i\\|^2\\right) \\propto \\\\ \\propto \\sum\\limits_{i = 1}^m E_{q(\\mathbf{Z})}\\left(-n\\log\\sigma - \\frac{1}{2\\sigma^2}\\|x_i- (\\mu + W z_i)\\|^2 + \\|z_i\\|^2\\right) \\propto \\\\ \\propto \\sum\\limits_{i = 1}^m \\left(-n\\log\\sigma - \\frac{1}{2\\sigma^2}(\\mathbf{x}_i^\\top\\mathbf{x}_i - 2\\mathbf{x}_i^\\top E_{q(\\mathbf{Z})}(\\mathbf{\\mu} + \\mathbf{W}\\mathbf{z}_i) + E_{q(\\mathbf{Z})}\\|\\mathbf{\\mu} + \\mathbf{W}\\mathbf{z}_i\\|^2) - E_{q(\\mathbf{Z})}\\|\\mathbf{z}_i\\|^2\\right) = \\\\ = \\sum\\limits_{i = 1}^m \\left(-n\\log\\sigma  - \\frac{1}{2\\sigma^2}(\\mathbf{x}_i^\\top\\mathbf{x}_i - 2\\mathbf{x}_i^\\top\\mathbf{\\mu} - 2\\mathbf{x}_i^\\top\\mathbf{W}E_{q(\\mathbf{Z})}\\mathbf{z}_i + \\mathbf{\\mu}^\\top\\mathbf{\\mu} + 2\\mathbf{\\mu}^\\top\\mathbf{W}E_{q(\\mathbf{Z})}\\mathbf{z}_i + E_{q(\\mathbf{Z})}\\mathbf{z}_i^\\top\\mathbf{W}^\\top\\mathbf{W}\\mathbf{z}_i) - E_{q(\\mathbf{Z})}\\|\\mathbf{z}_i\\|^2\\right) \\to \\underset{\\mathbf{\\mu}, \\sigma}{\\max}$$\n",
        "\n",
        "Возьмём частную производную по $\\mathbf{\\mu}$:\n",
        "\n",
        "$$\\sum\\limits_{i = 1}^m \\left(\\frac{1}{\\sigma^2}\\mathbf{x}_i - \\frac{1}{\\sigma^2}E_{q(\\mathbf{Z})}(\\mathbf{W}\\mathbf{z}_i + \\mathbf{\\mu})\\right) = 0$$\n",
        "\n",
        "Тогда:\n",
        "\n",
        "$$\\mathbf{\\mu}_{new} = \\frac{1}{m}\\sum\\limits_{i = 1}^m (\\mathbf{x}_i - \\mathbf{W}E_{q(\\mathbf{Z})}(\\mathbf{z}_i))$$\n",
        "\n",
        "Возьмём частную производную по $\\mathbf{W}$:\n",
        "\n",
        "$$\\sum\\limits_{i = 1}^m \\left(\\frac{1}{\\sigma^2}\\mathbf{x}_iE_{q(\\mathbf{Z})}(\\mathbf{z}_i^\\top) - \\frac{1}{\\sigma^2}E_{q(\\mathbf{Z})}((\\mathbf{W}\\mathbf{z}_i + \\mathbf{\\mu})\\mathbf{z}_i^\\top)\\right) = 0$$\n",
        "\n",
        "$$\\sum\\limits_{i = 1}^m \\left(\\mathbf{W}E_{q(\\mathbf{Z})}(\\mathbf{z}_i\\mathbf{z}_i^T) + (\\mathbf{\\mu} - \\mathbf{x}_i)E_{q(\\mathbf{Z})}(\\mathbf{z}_i)^\\top\\right) = 0$$\n",
        "\n",
        "Тогда:\n",
        "\n",
        "$$W_{new} = \\left(\\sum\\limits_{i = 1}^m (\\mathbf{x}_i - \\mathbf{\\mu})E_{q(\\mathbf{Z})}(\\mathbf{z}_i)^\\top\\right)\\left(\\sum\\limits_{i = 1}^m E_{q(\\mathbf{Z})}(\\mathbf{z}_i\\mathbf{z}_i^T)\\right)^{-1}$$\n",
        "\n",
        "Возьмём частную производную по $\\sigma^2$:\n",
        "\n",
        "$$\\sum\\limits_{i = 1}^m \\frac{1}{2\\sigma^4}E_{q(\\mathbf{Z})}\\left(\\|\\mathbf{W}\\mathbf{z}_i + \\mathbf{\\mu} - \\mathbf{x}_i\\|^2\\right) - \\frac{nm}{2\\sigma^2} = 0$$\n",
        "\n",
        "Тогда:\n",
        "\n",
        "$$\\sigma_{new}^2 = \\frac{1}{nm}\\sum\\limits_{i = 1}^m \\left(E_{q(\\mathbf{Z})}\\|\\mathbf{W}_{new}\\mathbf{z}_i\\|^2 + 2E_{q(\\mathbf{Z})}(\\mathbf{z}_i^T\\mathbf{W}_{new}^T(\\mathbf{\\mu}_{new} - \\mathbf{x}_i)) + \\|\\mathbf{\\mu}_{new} - \\mathbf{x}_i\\|^2\\right)$$"
      ],
      "metadata": {
        "id": "qcoLbDEciz9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем матожидания\n",
        "\n",
        "$$E_{q(\\mathbf{Z})}\\mathbf{z}_i = \\mathbf{m}_i = \\frac{A^\\top \\mathbf{W}^\\top}{\\sigma^2}(\\mathbf{x}_i - \\mathbf{\\mu}) = \\frac{(\\frac{\\mathbf{W}^\\top\\mathbf{W}}{\\sigma^2} + \\mathbf{I})^{-\\top}\\mathbf{W}^\\top}{\\sigma^2}(\\mathbf{x}_i - \\mathbf{\\mu})$$\n",
        "\n",
        "$$E_{q(\\mathbf{Z})}\\|\\mathbf{z}_i\\|^2 = E_{q(\\mathbf{Z})}\\sum\\limits_{j=1}^d z_{ij}^2 = \\sum\\limits_{j=1}^d D_{q(\\mathbf{Z})}\\mathbf{z}_{ij} + \\sum\\limits_{j=1}^d(E_{q(\\mathbf{Z})}\\mathbf{z}_{ij})^2 = \\sum\\limits_{j=1}^d A_{jj} + \\sum\\limits_{j=1}^d(\\mathbf{m}_{ij})^2 = \\text{tr}A + \\|\\mathbf{m}_i\\|^2$$\n",
        "\n",
        "$$E_{q(\\mathbf{Z})}\\|\\mathbf{W}_{new}\\mathbf{z}_i\\|^2 = E_{q(\\mathbf{Z})} \\sum\\limits_{j=1}^n(\\mathbf{W}_j\\mathbf{z}_i)^2 = \\sum\\limits_{j=1}^n D_{q(\\mathbf{Z})}(\\mathbf{W}_j\\mathbf{z}_i) + (E_{q(\\mathbf{Z})}\\mathbf{W}_j\\mathbf{z}_i)^2 = \\text{tr}(\\mathbf{W}A\\mathbf{W}^\\top) + \\|\\mathbf{W}\\mathbf{m}\n",
        "_i\\|^2$$\n",
        "\n",
        "Если есть пропущенные значения, то разобьём $\\mathbf{x}_i$ на $\\mathbf{x}_{i}^{true}, \\mathbf{x}_{i}^{miss}$. Тогда матрица $\\mathbf{X}$ разобьётся на $\\mathbf{X}^{true}, \\mathbf{X}^{miss}$. Запишем правдоподобие в этом случае:\n",
        "\n",
        "$$p(\\mathbf{X}^{true},\\mathbf{X}^{miss}, \\mathbf{Z}|\\mathbf{W}, \\mathbf{\\mu}, \\sigma) = \\prod\\limits_{i = 1}^n N(\\mathbf{x}_i^{true}|\\mu^{true} + \\mathbf{W}^{true} \\mathbf{z}_i, \\sigma^2\\mathbf{I})N(\\mathbf{x}_i^{miss}|\\mu^{miss} + \\mathbf{W}^{miss} \\mathbf{z}_i, \\sigma^2\\mathbf{I})N(\\mathbf{z}_i| 0, \\mathbf{I})$$\n",
        "\n",
        "Изменение в EM-алгоритме:\n",
        "\n",
        "$$q(\\mathbf{z}_i, \\mathbf{x}_i^{miss}) = p(\\mathbf{z}_i, \\mathbf{x}_i^{miss}|\\mathbf{x}_i^{true}, \\mathbf{W}, \\mathbf{\\mu}, \\sigma^2) \\sim N(\\mathbf{z}_i, \\mathbf{x}_i^{miss}|\\mathbf{m}_i, A)$$"
      ],
      "metadata": {
        "id": "uWX0U8NSj9-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ortho_group"
      ],
      "metadata": {
        "id": "Wqcq5UeN01Xf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "7HpI9W_y0tHb"
      },
      "outputs": [],
      "source": [
        "m = 1000\n",
        "n = 10\n",
        "d = 2\n",
        "sigma = 1\n",
        "\n",
        "Z = np.random.multivariate_normal(np.zeros(d), np.eye(d), m)\n",
        "eps = np.random.multivariate_normal(np.zeros(n), np.eye(n))\n",
        "W = ortho_group.rvs(dim=n)[:, :d] # Так проще будет найти обратную\n",
        "X = Z @ W.T + eps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_A(W, sigma):\n",
        "    return np.linalg.inv(W.T @ W / sigma**2  + np.eye(W.shape[1]))\n",
        "\n",
        "def get_m(W, X, mu, sigma):\n",
        "    A = get_A(W, sigma)\n",
        "    return A.T @ W.T @ (X - mu).T / sigma**2 #(2, 1000)\n",
        "\n",
        "def Ezz(W, X, mu, sigma):\n",
        "    m = get_m(W, X, mu, sigma)\n",
        "    A = get_A(W, sigma)\n",
        "    return np.full(X.shape[0], np.trace(A)) + np.linalg.norm(m, axis=0)**2 #(1000,)\n",
        "\n",
        "def EzWWz(W, X, mu, sigma):\n",
        "    m = get_m(W, X, mu, sigma)\n",
        "    A = get_A(W, sigma)\n",
        "    return np.full(X.shape[0], np.trace(W @ A @ W.T)) + np.linalg.norm(W @ m, axis=0)**2 #(1000,)\n",
        "\n",
        "def mu_new(W, X, mu, sigma):\n",
        "    return np.mean(X - (W @ get_m(W, X, mu, sigma)).T, axis=0)\n",
        "\n",
        "def W_new(W, X, mu, sigma):\n",
        "    m = get_m(W, X, mu, sigma)\n",
        "    matrix = np.zeros_like(W)\n",
        "    for i, row in enumerate(m.T):\n",
        "        matrix += np.outer((X[i] - mu), row)\n",
        "    return matrix / np.sum(Ezz(W, X, mu, sigma))\n",
        "\n",
        "def sigma_new(W, X, mu, sigma):\n",
        "    m, n = X.shape\n",
        "    v = np.zeros(m)\n",
        "    matrix = get_m(W, X, mu, sigma).T @ W.T\n",
        "    for i in range(m):\n",
        "        v[i] = matrix[i] @ (mu - X[i])\n",
        "    part = EzWWz(W, X, mu, sigma) + np.linalg.norm(mu - X, axis=1) + v\n",
        "    return np.sum(part) / (n * m)\n",
        "\n",
        "def EM(X, W, sigma, num_iter):\n",
        "    mu = np.mean(X, axis=0)\n",
        "    for k in range(num_iter):\n",
        "        mu = mu_new(W, X, mu, sigma)\n",
        "        W = W_new(W, X, mu, sigma)\n",
        "        sigma = sigma_new(W, X, mu, sigma)\n",
        "    return W, mu, sigma"
      ],
      "metadata": {
        "id": "20lx6uct1D3d"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_new, mu_new, sigma_new = EM(X, W, sigma, 100)"
      ],
      "metadata": {
        "id": "027Vz0TeFEbi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z_new = W_new.T @ (X - mu_new - eps).T\n",
        "Z_new.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKB9mzycH9WW",
        "outputId": "a02abb1c-6335-4fcd-ef49-91fea92c47a3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13128011,  0.12410065],\n",
              "       [-0.00188507, -0.15009897],\n",
              "       [-0.09428243, -0.14537584],\n",
              "       ...,\n",
              "       [-0.11545227,  0.00134787],\n",
              "       [-0.01582625, -0.06139569],\n",
              "       [-0.07176686, -0.18633137]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X)\n",
        "new_X = pca.transform(X)\n",
        "new_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AwgP9WcFUTP",
        "outputId": "22f7f894-d6e1-4065-82e0-aaf6e47a7706"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.96136658,  2.69478646],\n",
              "       [-0.17833727, -1.37989096],\n",
              "       [-1.01533236, -0.4570689 ],\n",
              "       ...,\n",
              "       [ 0.05119224,  1.26874019],\n",
              "       [ 0.4555844 , -0.32573011],\n",
              "       [-1.15527021, -1.0958304 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Матрицы разные. Возможно я ошиблась либо в формулах, либо в реализации..."
      ],
      "metadata": {
        "id": "XnNjaHATL3Oo"
      }
    }
  ]
}